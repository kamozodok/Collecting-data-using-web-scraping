{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hands-on Lab : Web Scraping**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30 to 45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract information from a given web site \n",
    "* Write the scraped data into a csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information from the given web site\n",
    "You will extract the data from the below web site: <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this url contains the data you need to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data you need to scrape is the **name of the programming language** and **average annual salary**.<br> It is a good idea to open the url in your web broswer and study the contents of the web page before you start to scrape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the webpage at the url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "data  = requests.get(url).text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No.', 'Language', 'Created By', 'Average Annual Salary', 'Learning Difficulty']\n",
      "['1', 'Python', 'Guido van Rossum', '$114,383', 'Easy']\n",
      "['2', 'Java', 'James Gosling', '$101,013', 'Easy']\n",
      "['3', 'R', 'Robert Gentleman, Ross Ihaka', '$92,037', 'Hard']\n",
      "['4', 'Javascript', 'Netscape', '$110,981', 'Easy']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download the webpage at the URL\n",
    "response = requests.get(url)\n",
    "data = response.text  # Get the HTML content of the page\n",
    "\n",
    "# Create a BeautifulSoup object by parsing the HTML content\n",
    "soup = BeautifulSoup(data, \"html.parser\")\n",
    "\n",
    "# Find the first table (since there might be multiple tables)\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# Loop through the first few rows to inspect the data\n",
    "for i, row in enumerate(rows[:5]):  # Checking the first 5 rows\n",
    "    cols = row.find_all(\"td\")  # Get all columns in the row\n",
    "    if len(cols) > 1:  # Ensure there are columns in the row\n",
    "        # Print the first few columns of the row\n",
    "        print([col.get_text(strip=True) for col in cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a soup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#your code goes here\n",
    "soup = BeautifulSoup(data, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the `Language name` and `annual average salary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Language Average Annual Salary\n",
      "0      Python                114383\n",
      "1        Java                101013\n",
      "2           R                 92037\n",
      "3  Javascript                110981\n",
      "4       Swift                130801\n",
      "5         C++                113865\n",
      "6          C#                 88726\n",
      "7         PHP                 84727\n",
      "8         SQL                 84793\n",
      "9          Go                 94082\n"
     ]
    }
   ],
   "source": [
    "#your code goes here\n",
    "# Find the first table (since there might be multiple tables)\n",
    "table = soup.find(\"table\")\n",
    "\n",
    "# Find all rows in the table\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# Create a list to store language names and salaries\n",
    "languages_and_salaries = []\n",
    "\n",
    "# Loop through each row and extract the language name and annual average salary\n",
    "for i, row in enumerate(rows):\n",
    "    cols = row.find_all(\"td\")  # Get all columns in the row\n",
    "    if len(cols) > 1 and i > 0:  # Skip the header row and ensure there are enough columns to extract the required data\n",
    "        language_name = cols[1].get_text(strip=True)  # Second column: Language name\n",
    "        avg_salary = cols[3].get_text(strip=True)  # Fourth column: Average annual salary\n",
    "        \n",
    "        # Clean the salary (remove '$' and commas)\n",
    "        avg_salary_clean = avg_salary.replace('$', '').replace(',', '')\n",
    "        \n",
    "        languages_and_salaries.append([language_name, avg_salary_clean])\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "df = pd.DataFrame(languages_and_salaries, columns=[\"Language\", \"Average Annual Salary\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scrapped data into a file named *popular-languages.csv*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to popular-languages.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the scraped data to a CSV file\n",
    "csv_filename = \"popular-languages.csv\"\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_filename, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write the header row\n",
    "    writer.writerow([\"Language\", \"Annual Average Salary\"])\n",
    "    \n",
    "    # Write each language and salary to the CSV file\n",
    "    for language, salary in languages_and_salaries:\n",
    "        writer.writerow([language, salary])\n",
    "\n",
    "print(f\"Data has been successfully saved to {csv_filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-10-17  | 0.1  | Ramesh Sannareddy  |  Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright &copy; 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
